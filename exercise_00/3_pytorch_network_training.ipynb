{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7x57SEGcohj"
   },
   "source": [
    "# Exercise 00\n",
    "## PyTorch Introduction - Part III\n",
    "\n",
    "### Goals of this tutorial\n",
    "\n",
    "- Understanding how to setup a basic training pipeline of pytorch using the example of image classification\n",
    "- Implementing different data augmentation techniques to improve image classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "This will setup your whole environment such that you can work with the rest of the notebook.\n",
    "\n",
    "### General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn                           # helpful for defining the network architecture\n",
    "import torch.optim as optim                     # helpful for setting up the optimizer\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up directory paths and (optionally) mount in Google Colab\n",
    "If you work with google colab set the `USING_COLAB` variable to `True` and following cell to mount your gdrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USING_COLAB = False\n",
    "USE_CPU = True\n",
    "# Use the following lines if you want to use Google Colab\n",
    "# We presume you created a folder \"cv3dst\" within your main drive folder, and put the exercise there.\n",
    "# NOTE: terminate all other colab sessions that use GPU!\n",
    "# NOTE 2: Make sure the correct exercise folder (e.g exercise_03) is given.\n",
    "\n",
    "if USING_COLAB:\n",
    "    from google.colab import drive\n",
    "    import os\n",
    "\n",
    "    gdrive_path='/content/gdrive/MyDrive/cv3dst/exercise_00'\n",
    "\n",
    "    # This will mount your google drive under 'MyDrive'\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    # In order to access the files in this notebook we have to navigate to the correct folder\n",
    "    os.chdir(gdrive_path)\n",
    "    # Check manually if all files are present\n",
    "    print(sorted(os.listdir()))\n",
    "    root_dir = Path(gdrive_path).parent\n",
    "else:\n",
    "    # depending on your folder structure, you might need to adapt this\n",
    "    root_dir = Path('./cv3dst/')\n",
    "dataset_dir = root_dir.joinpath(\"datasets\")\n",
    "output_dir = root_dir.joinpath('exercise_00', 'models')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() and not USE_CPU else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Specific Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code import train, Net\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setting up the `Dataset` and `DataLoader`\n",
    "\n",
    "Before tackling the training pipeline, we first need to prepare our data. In this example, we will revisit the task of image classification from I2DL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xqO2TAVcohx"
   },
   "source": [
    "### 3.1.1 Torchvision\n",
    "\n",
    "Specifically for computer vision, the `torchvision` packages has data loaders for many common datasets such\n",
    "as ImageNet, FashionMNIST, MNIST and additional data transformers for images in `torchvision.datasets` and `torch.utils.data.DataLoader` modules.\n",
    "\n",
    "This is highly convenient and is useful in avoiding  to write boilerplate code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8xwLhz_cohx"
   },
   "source": [
    "Let's try loading the [`Fashion-MNIST`](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset. It has  gray-scale images of size $28* 28$ belonging to 10 different classes of clothing accessories such as T-Shirt, Trousers, Sneakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJDpkaIccohx"
   },
   "source": [
    "`transforms.Compose` creates a series of transformation to prepare the dataset.\n",
    "- `transforms.ToTensor` convert `PIL image` or numpy.ndarray $(H \\times W\\times C)$ in the range [0,255] to a `torch.FloatTensor` of shape $(C \\times H \\times W)$ in the range [0.0, 1.0].\n",
    "\n",
    "- `transforms.Normalize` normalize a tensor image with the provided mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1666248234584,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "TDCQ-dU-cohx"
   },
   "outputs": [],
   "source": [
    "# Mean and standard deviations have to be sequences (e.g. tuples),hence we add a comma after the values\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTtnkHcUcohy"
   },
   "source": [
    "`datasets.FashionMNIST` downloads the Fashion MNIST dataset and transforms it using our previous cell definition.  \n",
    "By setting the value of `train`, we get the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1666248254510,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "88JgXArLcohy"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_dataset = torchvision.datasets.FashionMNIST(root='../datasets', train=True,\n",
    "                                                          download=True, transform=transform)\n",
    "fashion_mnist_test_dataset = torchvision.datasets.FashionMNIST(root='../datasets', train=False,\n",
    "                                                          download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Setting up the `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7m6DKn7cohy"
   },
   "source": [
    "\n",
    " `torch.utils.data.Dataloader` takes our training data or test data with parameter\n",
    "`batch_size` and `shuffle`. The variable `batch_size` defines how many samples per batch to load. The variable `shuffle=True` makes the data reshuffled at every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1666248279336,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "-np69cIWcohy"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_dataloader = DataLoader(fashion_mnist_dataset, batch_size=8)\n",
    "fashion_mnist_test_dataloader = DataLoader(fashion_mnist_test_dataset, batch_size=8)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvkwAM7qcohy"
   },
   "source": [
    "Let's look at the first batch of data from the `fashion_mnist_dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1666248293011,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "910zvAQqcohy",
    "outputId": "dc1347e8-b4fa-4c71-af56-4cdf546218fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can use the exact same way to iterate over samples\n",
    "for i, item in enumerate(fashion_mnist_dataloader):\n",
    "    print('Batch {}'.format(i))\n",
    "    image, label = item\n",
    "    print(f\"Datatype of Image: {type(image)}\")\n",
    "    print(f\"Shape of the Image: {image.shape}\")\n",
    "    print(f\"Label Values: {label}\")\n",
    "\n",
    "    if i+1 >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcrhgjq6cohz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we loaded the data with `batch_size` 8, the shape of the input is (8, 1, 28, 28). \n",
    "\n",
    "Let's look at  some of the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1666248331140,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "BddQv9nNcohz",
    "outputId": "a7f2d362-a8a6-49f4-ba84-dfca2427c482",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(fashion_mnist_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88wSqFzLcohz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Defining the Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rXu37WScohz"
   },
   "source": [
    "PyTorch provides a `nn.Module` that builds neural networks. Now, we will use it to define our network class. We define the network used in this task in <code>exercise_code/data/network</code> in the <code>Net</code> class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Kk_3zlGcoh0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looking at the constructor of `Net`, we have,\n",
    " - `super().__init__` creates a class that inherits attributes and behaviors from another class.\n",
    "\n",
    " - `self.fc1` creates an affine layer with `input_size` inputs and `hidden_size` outputs.\n",
    "\n",
    " - `self.fc2` is the second affine layer.\n",
    "\n",
    "The `Forward` function defines the forward pass of the mode.:\n",
    "\n",
    " - Input `x` is flattened with `x = x.view(-1, self.input_size)` to be able to use as input to the affine layer.\n",
    "\n",
    " - Apply `fc1`, `activation`, `fc2` sequentially to complete the network.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNfM9RMfcoh0"
   },
   "source": [
    "Central to all neural networks in PyTorch is the [`autograd`](https://pytorch.org/docs/stable/autograd.html) package. It provides automatic differentiation for all operations on Tensors. \n",
    "If we set the attribute `.requires_grad` of `torch.Tensor` as `True`, it tracks all operations applied on that tensor. Once all the computations are finished, the function `.backward()` computes the gradients into the `Tensor.grad` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ym0mkBCcoh0"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Thanks to the <b>autograd</b> package, we just have to define the <b>forward()</b> function. We can use any of the Tensor operations in the <b>forward()</b>  function.\n",
    " The <b>backward()</b> function (where gradients are computed through back-propagation) is automatically defined by PyTorch.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY_p41Xqcoh0"
   },
   "source": [
    "We can use `print()` to look at all the defined layers of the network (but it won't show the information of the forward pass).\n",
    "\n",
    "The learned parameters of a model are returned by `[model_name].parameters()`. We can also access the parameters of different layers by `[model_name].[layer_name].parameters()`.\n",
    "\n",
    "Let's create an instance of the `Net` model and look at the parameters matrix shape for each of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1666248605349,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "NmN67fa-coh0",
    "outputId": "44462da9-59c7-4d52-fada-e1a25fe2fefa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "# Always remember to move the network to the GPU/CPU depending on device\n",
    "net = net.to(device) \n",
    "\n",
    "print(net)\n",
    "\n",
    "print(\"Shapes of the Parameter Matrix:\")\n",
    "for parameter in net.parameters():\n",
    "        print(parameter.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhpMMhr_coh1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 Defining the Loss function and optimizer\n",
    "\n",
    "Since it is a multi-class classification, we will use the Cross-Entropy loss and optimize it using SGD with momentum. We had implemented SGD with momentum in Exercise 05. Have a look at the implementations in `exercise_code/networks/optimizer.py` and `exercise_code/networks/loss.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKVBSTxVcoh1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `torch.nn` and `torch.optim` modules include a variety of loss functions and optimizers. We will initialize an instance of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1666248659526,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "29fvTUYLcoh1",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clIzcvqbcoh1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4 Training the network\n",
    "\n",
    "We have completed setting up the dataloader, loss function as well as the optimizer. We are now all set for training the network.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Training a Neural Network</h3>\n",
    "    <p> These <b>ice-blue</b> cells mark tasks that you need to complete in order to pass an assignment. To clearly seperate these tasks and to not overfill the notebooks, the tasks are all located in python files under <code>exercise_code/data</code>. For this task, you will find the code you should complete under <a href=\"../exercise_00/exercise_code/data/train.py\"><code>exercise_code/data/train.py</code></a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>Test: Training a Neural Network</h3>\n",
    "    <p> In most cases, we try to provide some simple test cases for you to check your implementation. These are marked in <b>pink</b> and act as a guideline. Passing these tests does not guarantee passing the assingments. If you do not succed in passing a test, this should give you a hint on the possible location of problems. In this case, there is no test for your implementation.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35844,
     "status": "ok",
     "timestamp": 1666248829694,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "_y6yHNlGcoh1",
    "outputId": "5b1b5379-4b9a-4f80-94ac-704883e94842",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_epochs = 1\n",
    "train_loss_history, train_acc_history = train(net, fashion_mnist_dataloader, optimizer, criterion, max_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnpG_JJYcoh2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So the general training pass is summarized below:\n",
    "\n",
    "- `zero_grad()`: Zero the gradient buffers of all the model parameters to start the current minibatch iteration.\n",
    "\n",
    "- `y_pred = net(X)`: Make a forward pass through the network by passing the images to the model to get the predictions, which are log probabilities of image belonging to each of the class.\n",
    "\n",
    "- `loss = criterion(y_pred, y)`: Calculate the loss from the generated predictions and the training data `y`.\n",
    "\n",
    "- `loss.backward()`: Perform a backward pass through the network to calculate the gradients for model parameters.\n",
    "\n",
    "- `optimizer.step()`: Do an optimization step to update the model parameters using the calculated gradients.\n",
    "\n",
    "We keep tracking the training loss and accuracy over time. The following plot shows average values for train loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1666248840054,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "A-G7NTJkcoh2",
    "outputId": "3d1cc750-11ed-4a87-cd65-017f9fdee3e3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc_history)\n",
    "plt.plot(train_loss_history)\n",
    "plt.title(\"FashionMNIST\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('acc/loss')\n",
    "plt.legend(['acc', 'loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EAsLuiBcoh2"
   },
   "source": [
    "## 3.5 Testing the performance of the model\n",
    "\n",
    "We have trained the network for 2 passes over the entire training dataset. Let's check the model performance using the test data.\n",
    "We will pass the test data to the model to predict the class label and check it against the ground-truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1666248892013,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "t1jsFcgicoh3"
   },
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(fashion_mnist_test_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# get sample outputs\n",
    "outputs = net(images)\n",
    "# convert output probabilites to predicted class\n",
    "_, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY47J6Rycoh3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "We will visualize the results to display the test images and their labels in the following format: `predicted (ground-truth)`. The text will be green for accurately classified examples and red for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1666248899193,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "mFAnY6KLcoh3",
    "outputId": "70059b65-f7d7-46dd-be2a-1f9be9d9e716"
   },
   "outputs": [],
   "source": [
    "# prep images for display\n",
    "if not isinstance(images, np.ndarray):\n",
    "    images = images.cpu().numpy()\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "for idx in range(8):\n",
    "    ax = fig.add_subplot(2, 8//2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(f\"{classes[predicted[idx]]} ({classes[labels[idx]]})\",\n",
    "                color=\"green\" if predicted[idx]==labels[idx] else \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39sQ5AyYcoh3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's find which classes of images performed well, and the classes that did not perform well!  \n",
    "`torch.no_grad()` makes sure that gradients are not calculated for the tensors since we only are performing a forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3109,
     "status": "ok",
     "timestamp": 1666248960659,
     "user": {
      "displayName": "Dominik Muhle",
      "userId": "05194695185902771730"
     },
     "user_tz": -120
    },
    "id": "eKAhfLOHcoh3",
    "outputId": "bdfabae9-94fb-43a6-85a7-53e9281b16d0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in fashion_mnist_test_dataloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %11s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), output_dir.joinpath(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_code.submit import submit_exercise\n",
    "\n",
    "submit_exercise('../output/exercise00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h6ffzMtcoh4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. [PyTorch Tutorial](https://pytorch.org/tutorials/)\n",
    "\n",
    "2. [Fashion MNIST dataset training using PyTorch](https://medium.com/@aaysbt/fashion-mnist-data-training-using-pytorch-7f6ad71e96f4)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "17RqclroXTQLjK8oKvhf3_YgX4nx2lA7h",
     "timestamp": 1666019201411
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('cv3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b38045e10271186d31b9c7cfcf32f44b81f9b46f72bad763493647421023d2a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
